/// Demo showing complete swarm intelligence workflow
/// Scenario: Analyze customer feedback to generate actionable insights
///
/// This is a SIMULATION showing the architecture in action.
/// Real implementation would use actual LLM calls.

import 'package:micro/infrastructure/ai/agent/swarm/blackboard.dart';
import 'package:micro/infrastructure/serialization/toon_encoder.dart';

void main() {
  print('=' * 80);
  print('SWARM INTELLIGENCE DEMO');
  print('Scenario: Customer Feedback Analysis');
  print('=' * 80);
  print('');

  // Sample customer feedback data
  final customerFeedback = [
    "The UI is beautiful but the app crashes when I upload large files. Very frustrating!",
    "Love the new dark mode! Performance is great. Would give 5 stars if file sync worked better.",
    "App is slow on my old phone. Takes 10 seconds to open. But features are awesome.",
    "Best productivity app I've used. Only issue: can't export to PDF. Please add this!",
    "Keeps crashing. Fix the bugs! Otherwise good design.",
  ];

  print('ğŸ“‹ INPUT DATA:');
  print('Customer Reviews: ${customerFeedback.length} reviews');
  for (int i = 0; i < customerFeedback.length; i++) {
    print('  ${i + 1}. "${customerFeedback[i]}"');
  }
  print('');

  // USER TASK
  final userTask = """
Analyze these customer reviews and provide:
1. Overall sentiment (positive/negative/mixed)
2. Average satisfaction score (1-5)
3. Top 3 most mentioned issues
4. Top 3 most praised features
5. Recommended priority actions for product team
""";

  print('ğŸ¯ USER TASK:');
  print(userTask);
  print('');

  // PHASE 1: META-PLANNING
  // LLM analyzes task and generates specialist definitions
  print('=' * 80);
  print('PHASE 1: META-PLANNING (LLM generates specialist team)');
  print('=' * 80);
  print('');

  // Simulated LLM response - in real system, this comes from GLM-4.5
  final metaPlanResponse = {
    "goal":
        "Generate comprehensive customer feedback analysis with actionable insights",
    "specialists": [
      {
        "id": "spec_sentiment",
        "role": "sentiment_analyst",
        "systemPrompt":
            "Analyze text for sentiment. Output JSON: {\"sentiment\": \"positive|negative|neutral|mixed\", \"positive_count\": N, \"negative_count\": N, \"confidence\": 0-1}",
        "requiredTools": ["sentiment_simple_tool"],
        "subtask":
            "Classify overall sentiment and count positive vs negative reviews"
      },
      {
        "id": "spec_rating",
        "role": "rating_calculator",
        "systemPrompt":
            "Extract numeric ratings or infer rating from sentiment. Output JSON: {\"average_rating\": 1-5, \"ratings\": [list], \"method\": \"extracted|inferred\"}",
        "requiredTools": ["calculator_tool", "stats_tool"],
        "subtask": "Calculate average satisfaction score from reviews"
      },
      {
        "id": "spec_issues",
        "role": "issue_extractor",
        "systemPrompt":
            "Extract complaints and problems. Output JSON: {\"issues\": [{\"issue\": \"text\", \"count\": N, \"severity\": \"high|medium|low\"}]}",
        "requiredTools": ["knowledge_base_tool"],
        "subtask": "Identify and rank top issues mentioned in reviews"
      },
      {
        "id": "spec_praise",
        "role": "feature_praise_extractor",
        "systemPrompt":
            "Extract positive mentions of features. Output JSON: {\"praised_features\": [{\"feature\": \"text\", \"count\": N}]}",
        "requiredTools": ["knowledge_base_tool"],
        "subtask": "Identify most appreciated features from positive feedback"
      },
      {
        "id": "spec_synthesizer",
        "role": "insight_synthesizer",
        "systemPrompt":
            "Combine all blackboard data into final report. Output JSON: {\"summary\": \"text\", \"priority_actions\": [\"action1\", \"action2\", \"action3\"]}",
        "requiredTools": ["echo_tool"],
        "subtask":
            "Create final summary with prioritized action items for product team"
      }
    ]
  };

  final specialists = metaPlanResponse['specialists'] as List;
  print('ğŸ¤– LLM Generated ${specialists.length} Specialists:');
  for (final spec in specialists) {
    final specMap = spec as Map<String, dynamic>;
    print('');
    print('  Specialist: ${specMap['id']}');
    print('  Role: ${specMap['role']}');
    print('  Subtask: ${specMap['subtask']}');
    print('  Tools: ${specMap['requiredTools']}');
  }
  print('');

  // PHASE 2: SEQUENTIAL EXECUTION
  print('=' * 80);
  print('PHASE 2: SEQUENTIAL SPECIALIST EXECUTION');
  print('=' * 80);
  print('');

  final blackboard = Blackboard();
  int currentVersion = 0;

  // Specialist 1: Sentiment Analysis
  print('â”Œâ”€ Specialist 1: sentiment_analyst â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€');
  print('â”‚');
  print('â”‚ ğŸ“¥ INPUT (TOON format sent to LLM):');
  final spec1Input = {
    'reviews': customerFeedback,
  };
  print('â”‚ ${toonEncode(spec1Input).replaceAll('\n', '\nâ”‚ ')}');
  print('â”‚');
  print('â”‚ ğŸ”„ Analyzing sentiment...');

  // Simulated specialist execution (real system calls LLM here)
  final sentimentResult = {
    "sentiment": "mixed",
    "positive_count": 3,
    "negative_count": 2,
    "confidence": 0.85
  };

  print('â”‚');
  print('â”‚ ğŸ“¤ OUTPUT (from LLM):');
  print('â”‚ $sentimentResult');
  print('â”‚');
  print('â”‚ âœï¸  Writing to blackboard...');
  blackboard.put('sentiment', sentimentResult['sentiment'],
      author: 'spec_sentiment', confidence: 0.85);
  blackboard.put('positive_count', sentimentResult['positive_count'],
      author: 'spec_sentiment');
  blackboard.put('negative_count', sentimentResult['negative_count'],
      author: 'spec_sentiment');
  print('â”‚');
  print(
      'â”‚ âœ… Completed. Blackboard: ${blackboard.factCount} facts (v${blackboard.version})');
  print('â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€');
  print('');

  currentVersion = blackboard.version;

  // Specialist 2: Rating Calculator
  print('â”Œâ”€ Specialist 2: rating_calculator â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€');
  print('â”‚');
  print('â”‚ ğŸ“¥ INPUT (TOON delta - only new facts):');
  final delta = blackboard.getDelta(currentVersion - 3); // Show what was added
  final deltaData = delta
      .map((e) => {'key': e.key, 'value': e.value, 'by': e.author})
      .toList();
  print(
      'â”‚ ${toonEncode({'recent_facts': deltaData}).replaceAll('\n', '\nâ”‚ ')}');
  print('â”‚');
  print('â”‚ ğŸ”„ Calculating average rating...');

  final ratingResult = {
    "average_rating": 3.8,
    "ratings": [3, 5, 2, 4, 3],
    "method": "inferred"
  };

  print('â”‚');
  print('â”‚ ğŸ“¤ OUTPUT:');
  print('â”‚ $ratingResult');
  print('â”‚');
  print('â”‚ âœï¸  Writing to blackboard...');
  blackboard.put('average_rating', ratingResult['average_rating'],
      author: 'spec_rating', confidence: 0.75);
  blackboard.put('rating_method', ratingResult['method'],
      author: 'spec_rating');
  print('â”‚');
  print(
      'â”‚ âœ… Completed. Blackboard: ${blackboard.factCount} facts (v${blackboard.version})');
  print('â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€');
  print('');

  currentVersion = blackboard.version;

  // Specialist 3: Issue Extractor
  print('â”Œâ”€ Specialist 3: issue_extractor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€');
  print('â”‚');
  print('â”‚ ğŸ“¥ INPUT (Reviews + existing blackboard state):');
  print('â”‚ Blackboard TOON (~60% smaller than JSON):');
  final bbTOON = blackboard.toTOON();
  print('â”‚ ${bbTOON.replaceAll('\n', '\nâ”‚ ')}');
  print(
      'â”‚ Size: ${bbTOON.length} chars (vs ${blackboard.toJSON().length} JSON)');
  print(
      'â”‚ Savings: ${((blackboard.toJSON().length - bbTOON.length) / blackboard.toJSON().length * 100).toStringAsFixed(1)}%');
  print('â”‚');
  print('â”‚ ğŸ”„ Extracting top issues...');

  final issuesResult = {
    "issues": [
      {"issue": "App crashes/stability", "count": 3, "severity": "high"},
      {
        "issue": "Slow performance on older devices",
        "count": 2,
        "severity": "medium"
      },
      {"issue": "File upload/sync problems", "count": 2, "severity": "medium"},
    ]
  };

  print('â”‚');
  print('â”‚ ğŸ“¤ OUTPUT:');
  final issues = issuesResult['issues'] as List;
  for (final issue in issues) {
    final issueMap = issue as Map<String, dynamic>;
    print(
        'â”‚   - ${issueMap['issue']} (count: ${issueMap['count']}, severity: ${issueMap['severity']})');
  }
  print('â”‚');
  print('â”‚ âœï¸  Writing to blackboard...');
  blackboard.put('top_issues', issuesResult['issues'],
      author: 'spec_issues', confidence: 0.9);
  print('â”‚');
  print(
      'â”‚ âœ… Completed. Blackboard: ${blackboard.factCount} facts (v${blackboard.version})');
  print('â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€');
  print('');

  currentVersion = blackboard.version;

  // Specialist 4: Feature Praise Extractor
  print('â”Œâ”€ Specialist 4: feature_praise_extractor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€');
  print('â”‚');
  print('â”‚ ğŸ“¥ INPUT (Delta since last specialist):');
  final delta2 = blackboard.getDelta(currentVersion - 1);
  print('â”‚ New facts: ${delta2.length}');
  print('â”‚');
  print('â”‚ ğŸ”„ Extracting praised features...');

  final praiseResult = {
    "praised_features": [
      {"feature": "UI/Design/Dark mode", "count": 3},
      {"feature": "Features/Functionality", "count": 2},
      {"feature": "Performance (when working)", "count": 1},
    ]
  };

  print('â”‚');
  print('â”‚ ğŸ“¤ OUTPUT:');
  final features = praiseResult['praised_features'] as List;
  for (final feature in features) {
    final featureMap = feature as Map<String, dynamic>;
    print(
        'â”‚   - ${featureMap['feature']} (mentioned: ${featureMap['count']}x)');
  }
  print('â”‚');
  print('â”‚ âœï¸  Writing to blackboard...');
  blackboard.put('praised_features', praiseResult['praised_features'],
      author: 'spec_praise', confidence: 0.88);
  print('â”‚');
  print(
      'â”‚ âœ… Completed. Blackboard: ${blackboard.factCount} facts (v${blackboard.version})');
  print('â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€');
  print('');

  // Specialist 5: Synthesizer
  print('â”Œâ”€ Specialist 5: insight_synthesizer â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€');
  print('â”‚');
  print('â”‚ ğŸ“¥ INPUT (Complete blackboard state):');
  print('â”‚ All facts accumulated from 4 specialists:');
  final allFacts = blackboard.getAllFacts();
  print('â”‚   ${allFacts.keys.join(', ')}');
  print('â”‚');
  print('â”‚ ğŸ”„ Synthesizing final report...');

  final synthesisResult = {
    "summary":
        "Customer feedback shows mixed sentiment (3/5 positive, 2/5 negative) with an average rating of 3.8/5. Users love the UI and features but are frustrated by critical stability issues.",
    "priority_actions": [
      "P0: Fix app crashes and stability issues (affects 60% of reviewers)",
      "P1: Optimize performance for older/lower-end devices",
      "P2: Improve file upload/sync reliability (major pain point)",
    ]
  };

  print('â”‚');
  print('â”‚ ğŸ“¤ OUTPUT:');
  print('â”‚');
  print('â”‚ Summary:');
  print('â”‚   ${synthesisResult['summary']}');
  print('â”‚');
  print('â”‚ Priority Actions:');
  final actions = synthesisResult['priority_actions'] as List;
  for (final action in actions) {
    print('â”‚   âœ“ $action');
  }
  print('â”‚');
  print('â”‚ âœï¸  Writing to blackboard...');
  blackboard.put('final_summary', synthesisResult['summary'],
      author: 'spec_synthesizer');
  blackboard.put('priority_actions', synthesisResult['priority_actions'],
      author: 'spec_synthesizer');
  print('â”‚');
  print(
      'â”‚ âœ… Completed. Blackboard: ${blackboard.factCount} facts (v${blackboard.version})');
  print('â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€');
  print('');

  // PHASE 3: VERIFICATION & CONVERGENCE
  print('=' * 80);
  print('PHASE 3: VERIFICATION & CONVERGENCE CHECK');
  print('=' * 80);
  print('');

  print('ğŸ” Conflict Detection:');
  final conflicts = blackboard.detectConflicts();
  if (conflicts.isEmpty) {
    print('  âœ… No conflicts detected. All specialists agreed.');
  } else {
    print('  âš ï¸  Conflicts found in: ${conflicts.join(', ')}');
    for (final key in conflicts) {
      print('  Resolving $key...');
      blackboard.resolveConflict(key);
    }
  }
  print('');

  print('âœ“ Goal Achievement Check:');
  print('  âœ… Overall sentiment: ${blackboard.get('sentiment')}');
  print('  âœ… Average rating: ${blackboard.get('average_rating')}/5');
  print(
      '  âœ… Top issues: ${(blackboard.get('top_issues') as List).length} identified');
  print(
      '  âœ… Praised features: ${(blackboard.get('praised_features') as List).length} identified');
  print(
      '  âœ… Priority actions: ${(blackboard.get('priority_actions') as List).length} recommended');
  print('');
  print('ğŸ‰ CONVERGENCE ACHIEVED - All objectives met!');
  print('');

  // FINAL RESULTS
  print('=' * 80);
  print('FINAL RESULTS');
  print('=' * 80);
  print('');

  print('ğŸ“Š STATISTICS:');
  print('  Specialists used: 5');
  print('  Total blackboard facts: ${blackboard.factCount}');
  print('  Blackboard versions: ${blackboard.version}');
  print('  Conflicts detected: ${conflicts.length}');
  print('');

  print('ğŸ’° ESTIMATED TOKEN USAGE (with TOON optimization):');
  final totalChars =
      bbTOON.length * 5; // Rough estimate for all specialist calls
  final estimatedTokens = (totalChars / 4).ceil(); // ~4 chars per token
  final estimatedCost =
      (estimatedTokens / 1000000) * 0.6; // GLM-4.5 input pricing
  print('  Input tokens: ~$estimatedTokens');
  print('  Cost (GLM-4.5): ~\$${estimatedCost.toStringAsFixed(4)}');
  print('  (GLM-4.5-Flash: \$0.00 - FREE!)');
  print('');

  print('ğŸ“ FINAL ANSWER TO USER:');
  print('');
  print('â”€' * 80);
  print(blackboard.get('final_summary'));
  print('');
  print('Top Issues:');
  for (final issue in blackboard.get('top_issues')) {
    print(
        '  ${issue['severity'].toString().toUpperCase()}: ${issue['issue']} (${issue['count']} mentions)');
  }
  print('');
  print('Most Praised Features:');
  for (final feature in blackboard.get('praised_features')) {
    print('  â­ ${feature['feature']} (${feature['count']} mentions)');
  }
  print('');
  print('Recommended Actions:');
  for (final action in blackboard.get('priority_actions')) {
    print('  â†’ $action');
  }
  print('â”€' * 80);
  print('');

  print('=' * 80);
  print('KEY ARCHITECTURAL BENEFITS DEMONSTRATED');
  print('=' * 80);
  print('');
  print(
      'âœ“ Dynamic Specialist Creation: LLM generated 5 task-specific specialists');
  print(
      'âœ“ Sequential Execution: Safe on mobile, each specialist ~15MB, total ~170MB');
  print('âœ“ Blackboard Coordination: 9 facts written, 0 conflicts');
  print('âœ“ TOON Optimization: ~45% token savings vs JSON');
  print(
      'âœ“ Delta Updates: Each specialist sees only new facts (efficient context)');
  print('âœ“ Convergence: Goal achieved without replanning cycles');
  print(
      'âœ“ Cost Control: User can limit max_specialists (default 3 vs 5 used here)');
  print('');
  print(
      'ğŸ’¡ User would configure: max_specialists=3 to skip specialists 4-5 for faster/cheaper results');
  print('');
}
