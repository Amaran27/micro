import 'package:flutter/foundation.dart';
import 'dart:convert';
import 'dart:math';
import 'package:langchain/langchain.dart';
import 'package:langchain_openai/langchain_openai.dart';
import '../agent/agent_types.dart' as agent_types;

/// AI service for model integration and tool execution
class AIService {
  final ChatOpenAI _model;
  final Map<String, dynamic> _configuration;

  AIService({
    required String apiKey,
    String model = 'gpt-4',
    double temperature = 0.7,
    Map<String, dynamic>? configuration,
  })  : _model = ChatOpenAI(
          apiKey: apiKey,
          model: model,
          temperature: temperature,
        ),
        _configuration = configuration ?? {};

  /// Execute a single AI task
  Future<agent_types.AgentResult> executeTask({
    required String task,
    Map<String, dynamic>? context,
    int? maxTokens,
  }) async {
    try {
      final systemPrompt = _buildSystemPrompt(context ?? {});

      final messages = [
        ChatMessage.system(systemPrompt),
        ChatMessage.humanText(task),
      ];

      final result = await _model.invoke(
        PromptValue.chat(messages),
        options: ChatOpenAIOptions(maxTokens: maxTokens ?? 1000),
      );

      return agent_types.AgentResult(
        result: result.outputAsString,
        success: true,
        steps: [
          agent_types.AgentStep(
            stepId: 'ai_execution',
            description: 'AI model execution',
            type: agent_types.AgentStepType.reasoning,
            input: {'task': task, 'context': context},
            output: {'response': result.outputAsString},
            timestamp: DateTime.now(),
          ),
        ],
        metadata: {
          'model': 'gpt-4',
          'temperature': 0.7,
          'tokens_used': result.usage.totalTokens,
          'execution_time_ms': DateTime.now().millisecondsSinceEpoch,
        },
      );
    } catch (e, stackTrace) {
      debugPrint('AI service error: $e');
      return agent_types.AgentResult(
        result: 'Error executing AI task: $e',
        success: false,
        steps: [
          agent_types.AgentStep(
            stepId: 'error',
            description: 'AI execution failed',
            type: agent_types.AgentStepType.errorRecovery,
            timestamp: DateTime.now(),
          ),
        ],
        error: e.toString(),
        metadata: {
          'stack_trace': stackTrace.toString(),
          'timestamp': DateTime.now().millisecondsSinceEpoch,
        },
      );
    }
  }

  /// Execute task with tools
  Future<agent_types.AgentResult> executeWithTools({
    required String task,
    required List<BaseTool> tools,
    Map<String, dynamic>? context,
  }) async {
    try {
      final agent = OpenAIAgent(
        model: _model,
        tools: tools,
      );

      final agentResult = await agent.run(
        task,
        context: context ?? {},
      );

      return agent_types.AgentResult(
        result: agentResult.output,
        success: agentResult.success,
        steps: agentResult.steps
            .map((step) => agent_types.AgentStep(
                  stepId: step.id,
                  description: step.description,
                  type: _mapStepType(step.type),
                  input: step.input != null
                      ? Map<String, dynamic>.from(step.input!)
                      : null,
                  output: step.output != null
                      ? Map<String, dynamic>.from(step.output!)
                      : null,
                  timestamp: step.timestamp,
                  duration: step.duration,
                ))
            .toList(),
        error: agentResult.error,
        metadata: agentResult.metadata,
      );
    } catch (e, stackTrace) {
      debugPrint('AI service tool execution error: $e');
      return agent_types.AgentResult(
        result: 'Error executing AI task with tools: $e',
        success: false,
        steps: [
          agent_types.AgentStep(
            stepId: 'tool_error',
            description: 'AI tool execution failed',
            type: agent_types.AgentStepType.errorRecovery,
            timestamp: DateTime.now(),
          ),
        ],
        error: e.toString(),
        metadata: {
          'stack_trace': stackTrace.toString(),
          'timestamp': DateTime.now().millisecondsSinceEpoch,
        },
      );
    }
  }

  /// Generate structured response
  Future<T> generateStructured<T>({
    required String prompt,
    required T Function(Map<String, dynamic>) fromJson,
    Map<String, dynamic>? context,
    String? jsonSchema,
  }) async {
    try {
      final systemPrompt = _buildStructuredSystemPrompt(jsonSchema ?? '');

      final messages = [
        ChatMessage.system(systemPrompt),
        ChatMessage.humanText(prompt),
      ];

      final result = await _model.invoke(
        PromptValue.chat(messages),
        options: const ChatOpenAIOptions(),
      );

      final jsonResponse =
          jsonDecode(result.outputAsString) as Map<String, dynamic>;
      return fromJson(jsonResponse);
    } catch (e) {
      debugPrint('Structured generation error: $e');
      rethrow;
    }
  }

  /// Create specialized agent for specific tasks
  Future<agent_types.Agent> createSpecializedAgent({
    required agent_types.AgentType type,
    required String name,
    required String description,
    List<String>? capabilities,
    Map<String, dynamic>? configuration,
  }) async {
    final aiCapabilities =
        await _detectAgentCapabilities(type, capabilities ?? []);

    final agentConfig = {
      ..._configuration,
      ...configuration,
      'type': type.name,
      'name': name,
      'description': description,
      'capabilities': aiCapabilities,
      'created_at': DateTime.now().toIso8601String(),
    };

    return agent_types.Agent(
      id: _generateAgentId(),
      name: name,
      description: description,
      type: type,
      status: agent_types.AgentStatus.idle,
      capabilities: aiCapabilities
          .map((cap) => agent_types.AgentCapability(
                name: cap['name'],
                description: cap['description'],
              ))
          .toList(),
      configuration: agentConfig,
      createdAt: DateTime.now(),
    );
  }

  String _buildSystemPrompt(Map<String, dynamic> context) {
    return '''
You are an AI assistant integrated into a mobile application. 

Context: ${jsonEncode(context)}

Instructions:
- Provide clear, concise responses
- Be helpful and informative
- If you need to use tools, indicate which tool you would use
- For complex tasks, break them down into steps
- Always consider the mobile context (battery, data, performance)
- Keep responses focused on the user's specific request
''';
  }

  String _buildStructuredSystemPrompt(String jsonSchema) {
    return '''
You are an AI assistant that provides structured responses in JSON format.

JSON Schema: $jsonSchema

Instructions:
- Respond only with valid JSON
- Follow the provided schema exactly
- Do not include explanatory text outside the JSON
- Ensure all required fields are present
- Use appropriate data types for each field
''';
  }

  Future<List<Map<String, dynamic>>> _detectAgentCapabilities(
    agent_types.AgentType type,
    List<String> baseCapabilities,
  ) async {
    final defaultCapabilities = {
      agent_types.AgentType.general: [
        {
          'name': 'text_analysis',
          'description': 'Analyze and process text content',
          'inputTypes': ['text'],
          'outputTypes': ['analysis', 'summary'],
        },
        {
          'name': 'information_retrieval',
          'description': 'Retrieve and provide information',
          'inputTypes': ['query'],
          'outputTypes': ['information'],
        },
      ],
      agent_types.AgentType.specialized: baseCapabilities
          .map((cap) => {
                'name': cap,
                'description': 'Specialized capability: $cap',
                'inputTypes': ['task'],
                'outputTypes': ['result'],
              })
          .toList(),
      agent_types.AgentType.collaborative: [
        {
          'name': 'team_coordination',
          'description': 'Coordinate tasks between multiple agents',
          'inputTypes': ['team', 'tasks'],
          'outputTypes': ['coordination_plan'],
        },
        {
          'name': 'resource_sharing',
          'description': 'Share resources between agents',
          'inputTypes': ['resources'],
          'outputTypes': ['shared_resources'],
        },
      ],
    };

    return defaultCapabilities[type] ?? [];
  }

  agent_types.AgentStepType _mapStepType(String typeStr) {
    switch (typeStr) {
      case 'planning':
        return agent_types.AgentStepType.planning;
      case 'reasoning':
        return agent_types.AgentStepType.reasoning;
      case 'tool_execution':
        return agent_types.AgentStepType.toolExecution;
      case 'reflection':
        return agent_types.AgentStepType.reflection;
      case 'error_recovery':
        return agent_types.AgentStepType.errorRecovery;
      case 'finalization':
        return agent_types.AgentStepType.finalization;
      default:
        return agent_types.AgentStepType.reasoning;
    }
  }

  String _generateAgentId() {
    return 'agent_${DateTime.now().millisecondsSinceEpoch}_${Random().nextInt(9999)}';
  }

  /// Update model configuration
  void updateConfiguration({
    String? model,
    double? temperature,
    int? maxTokens,
  }) {
    // Note: Configuration updates would need to create a new ChatOpenAI instance
    // For now, we'll track these settings locally
    if (model != null) _configuration['model'] = model;
    if (temperature != null) _configuration['temperature'] = temperature;
  }

  /// Get current model information
  Map<String, dynamic> getModelInfo() {
    return {
      'model': _configuration['model'] ?? 'gpt-4',
      'temperature': _configuration['temperature'] ?? 0.7,
      'has_api_key': _model.apiKey.isNotEmpty,
    };
  }
}
