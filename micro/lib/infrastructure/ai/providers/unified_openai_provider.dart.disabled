import 'package:langchain_openai/langchain_openai.dart';
import 'package:dio/dio.dart';

import '../../../core/utils/logger.dart';
import '../secure_api_storage.dart';
import '../../../domain/models/ai_model.dart';

/// Unified OpenAI-compatible provider for all OpenAI-compatible APIs
/// This provider can handle OpenAI, ZhipuAI, and other OpenAI-compatible APIs
/// by simply changing the base URL and authentication details
class UnifiedOpenAIProvider {
  final AppLogger _logger = AppLogger();
  final Dio _dio = Dio();

  /// Provider configurations
  static const Map<String, ProviderConfig> _providerConfigs = {
    'openai': ProviderConfig(
      baseUrl: 'https://api.openai.com/v1',
      authHeader: 'Authorization',
      authPrefix: 'Bearer ',
      defaultModel: 'gpt-4',
    ),
    'zhipuai': ProviderConfig(
      baseUrl: 'https://api.z.ai/api/coding/paas/v4',
      authHeader: 'Authorization',
      authPrefix: 'Bearer ',
      defaultModel: 'glm-4.6',
    ),
    'azure': ProviderConfig(
      baseUrl: 'https://your-resource.openai.azure.com/openai/deployments/{deployment}',
      authHeader: 'api-key',
      authPrefix: '',
      defaultModel: 'gpt-4',
      isAzure: true,
    ),
  };

  /// Initialize provider for specific AI service
  Future<ChatOpenAI?> initialize(String providerName) async {
    try {
      final config = _providerConfigs[providerName];
      if (config == null) {
        _logger.error('Unknown provider: $providerName');
        return null;
      }

      final apiKey = await SecureApiStorage.getApiKey(providerName);
      if (apiKey == null || apiKey.isEmpty) {
        _logger.warning('$providerName API key not found');
        return null;
      }

      return _createChatModel(providerName, config, apiKey);
    } catch (e) {
      _logger.error('Failed to initialize $providerName provider', error: e);
      return null;
    }
  }

  /// Create chat model using OpenAI interface
  ChatOpenAI _createChatModel(String providerName, ProviderConfig config, String apiKey) {
    final headers = <String, String>{};
    headers[config.authHeader] = '${config.authPrefix}$apiKey';

    return ChatOpenAI(
      apiKey: apiKey,
      baseUrl: config.baseUrl,
      defaultOptions: ChatOpenAIOptions(
        model: config.defaultModel,
        maxTokens: 4000,
        temperature: 0.7,
      ),
      headers: headers,
    );
  }

  /// Get available models for provider
  Future<List<AIModel>> getAvailableModels(String providerName) async {
    try {
      final config = _providerConfigs[providerName];
      if (config == null) {
        _logger.error('Unknown provider: $providerName');
        return [];
      }

      final apiKey = await SecureApiStorage.getApiKey(providerName);
      if (apiKey == null || apiKey.isEmpty) {
        return _getDefaultModels(providerName);
      }

      // Standard OpenAI-compatible models endpoint
      final response = await _dio.get(
        '${config.baseUrl}/models',
        options: Options(
          headers: {
            config.authHeader: '${config.authPrefix}$apiKey',
            'Content-Type': 'application/json',
          },
        ),
      );

      if (response.statusCode == 200) {
        final data = response.data;
        final models = <AIModel>[];

        if (data['data'] != null) {
          for (final model in data['data']) {
            if (model['id'] != null) {
              models.add(AIModel(
                provider: providerName,
                modelId: model['id'],
                displayName: _getDisplayName(providerName, model['id']),
                description: model['description'] ?? '$providerName model',
                metadata: {
                  'capabilities': _getModelCapabilities(providerName, model['id']),
                  'contextWindow': _getContextWindow(providerName, model['id']),
                  'pricing': _getModelPricing(providerName, model['id']),
                  'created': model['created'],
                  'ownedBy': model['owned_by'] ?? providerName,
                },
              ));
            }
          }
        }

        _logger.info('Successfully fetched ${models.length} models from $providerName API');
        return models.isNotEmpty ? models : _getDefaultModels(providerName);
      } else {
        _logger.warning('Failed to fetch $providerName models: ${response.statusCode}');
        return _getDefaultModels(providerName);
      }
    } catch (e) {
      _logger.warning('Error fetching $providerName models, using defaults', error: e);
      return _getDefaultModels(providerName);
    }
  }

  /// Get default models for each provider
  List<AIModel> _getDefaultModels(String providerName) {
    switch (providerName) {
      case 'openai':
        return [
          AIModel(
            provider: 'openai',
            modelId: 'gpt-4',
            displayName: 'GPT-4',
            description: 'Most capable GPT-4 model',
            metadata: {
              'capabilities': ['text', 'reasoning', 'coding', 'analysis'],
              'contextWindow': 8192,
              'pricing': {'input': 0.03, 'output': 0.06},
            },
          ),
          AIModel(
            provider: 'openai',
            modelId: 'gpt-3.5-turbo',
            displayName: 'GPT-3.5 Turbo',
            description: 'Fast and efficient model',
            metadata: {
              'capabilities': ['text', 'reasoning', 'coding'],
              'contextWindow': 4096,
              'pricing': {'input': 0.0015, 'output': 0.002},
            },
          ),
        ];
      case 'zhipuai':
        return [
          AIModel(
            provider: 'zhipuai',
            modelId: 'glm-4.6',
            displayName: 'GLM-4.6',
            description: 'Latest flagship model with enhanced capabilities',
            metadata: {
              'capabilities': ['text', 'reasoning', 'coding', 'analysis'],
              'contextWindow': 128000,
              'pricing': {'input': 0.1, 'output': 0.1},
            },
          ),
          AIModel(
            provider: 'zhipuai',
            modelId: 'glm-4.5',
            displayName: 'GLM-4.5',
            description: 'Balanced performance model for general tasks',
            metadata: {
              'capabilities': ['text', 'reasoning', 'coding'],
              'contextWindow': 128000,
              'pricing': {'input': 0.05, 'output': 0.05},
            },
          ),
        ];
      default:
        return [];
    }
  }

  /// Get display name for model
  String _getDisplayName(String providerName, String modelId) {
    switch (providerName) {
      case 'openai':
        return modelId.toUpperCase().replaceAll('GPT-', 'GPT-');
      case 'zhipuai':
        return modelId.toUpperCase().replaceAll('GLM-', 'GLM-');
      default:
        return modelId.split('-').map((word) => 
          word[0].toUpperCase() + word.substring(1)
        ).join(' ');
    }
  }

  /// Get model capabilities
  List<String> _getModelCapabilities(String providerName, String modelId) {
    const baseCapabilities = ['text', 'reasoning'];
    
    if (modelId.contains('gpt-4') || modelId.contains('glm-4.6')) {
      return [...baseCapabilities, 'coding', 'analysis', 'math'];
    }
    
    if (modelId.contains('turbo') || modelId.contains('glm-4.5')) {
      return [...baseCapabilities, 'coding'];
    }
    
    return baseCapabilities;
  }

  /// Get context window size
  int _getContextWindow(String providerName, String modelId) {
    if (modelId.contains('128k') || modelId.contains('glm-4')) {
      return 128000;
    }
    if (modelId.contains('gpt-4')) {
      return 8192;
    }
    return 4096;
  }

  /// Get model pricing (per 1M tokens)
  Map<String, double> _getModelPricing(String providerName, String modelId) {
    switch (providerName) {
      case 'openai':
        if (modelId.contains('gpt-4')) {
          return {'input': 0.03, 'output': 0.06};
        }
        return {'input': 0.0015, 'output': 0.002};
      case 'zhipuai':
        if (modelId.contains('glm-4.6')) {
          return {'input': 0.1, 'output': 0.1};
        }
        return {'input': 0.05, 'output': 0.05};
      default:
        return {'input': 0.01, 'output': 0.02};
    }
  }
}

/// Configuration for each provider
class ProviderConfig {
  final String baseUrl;
  final String authHeader;
  final String authPrefix;
  final String defaultModel;
  final bool isAzure;

  const ProviderConfig({
    required this.baseUrl,
    required this.authHeader,
    required this.authPrefix,
    required this.defaultModel,
    this.isAzure = false,
  });
}