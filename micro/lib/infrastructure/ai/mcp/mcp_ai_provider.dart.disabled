import 'package:riverpod/riverpod.dart';
import 'package:langchain/langchain.dart';
import 'package:langchain_openai/langchain_openai.dart';
import 'package:anthropic_sdk_dart/anthropic_sdk_dart.dart';
import 'package:ollama_dart/ollama_dart.dart';
import 'mcp_client_adapter.dart';

/// Provider for MCP AI functionality
class McpAIProvider extends StateNotifier<AsyncValue<AIResponse>> {
  final Ref ref;
  
  MCPClientAdapter? _mcpAdapter;
  bool _isInitialized = false;
  
  McpAIProvider(this.ref) : super(const AsyncValue.loading());
  
  /// Initialize MCP provider with adapter
  Future<void> initialize(MCPClientConfig config) async {
    state = const AsyncValue.loading();
    
    try {
      // Initialize MCP client adapter
      _mcpAdapter = MCPClientAdapter();
      await _mcpAdapter!.initialize(config);
      
      // List available tools
      final tools = await _mcpAdapter!.listTools();
      
      state = AsyncValue.data(AIResponse(
        success: true,
        message: 'MCP provider initialized with ${tools.length} tools available',
        tools: tools.map(_convertMcpToolToLangChain).toList(),
      ));
      
      _isInitialized = true;
    } catch (e, stack) {
      state = AsyncValue.error(e, stack);
    }
  }
  
  /// Convert MCP tool to LangChain tool
  ChatTool _convertMcpToolToLangChain(Tool mcpTool) {
    return ChatTool(
      name: mcpTool.name,
      description: mcpTool.description ?? '',
      inputJsonSchema: mcpTool.inputSchema,
      function: (parameters) async {
        if (!_isInitialized || _mcpAdapter == null) {
          throw Exception('MCP provider not initialized');
        }
        
        try {
          final result = await _mcpAdapter!.callTool(mcpTool.name, arguments: parameters);
          return result.content.map((content) => content.toString()).join('\n');
        } catch (e) {
          throw Exception('Failed to execute MCP tool ${mcpTool.name}: $e');
        }
      },
    );
  }
  
  /// Execute AI request with MCP tools
  Future<AIResponse> executeRequest({
    required String prompt,
    String? model,
    Map<String, dynamic>? options,
  }) async {
    if (!_isInitialized || _mcpAdapter == null) {
      return AIResponse(
        success: false,
        message: 'MCP provider not initialized',
      );
    }
    
    state = const AsyncValue.loading();
    
    try {
      // Get available tools
      final mcpTools = await _mcpAdapter!.listTools();
      final langChainTools = mcpTools.map(_convertMcpToolToLangChain).toList();
      
      // Use default LLM from your existing providers
      // This would integrate with your existing Riverpod setup
      final llm = OpenAI(
        apiKey: 'your-api-key', // Would come from your config
        model: model ?? 'gpt-4-turbo',
      );
      
      // Create prompt with tools
      final chatPrompt = ChatPrompt.template(
        [ChatMessage.humanText(prompt)],
        tools: langChainTools,
      );
      
      // Generate response
      final result = await llm.generate([chatPrompt], options: options);
      
      final responseText = result.output;
      
      // Extract tool calls from response if any
      final toolCalls = result.toolCalls ?? [];
      
      return AIResponse(
        success: true,
        message: responseText,
        toolCalls: toolCalls.map((call) => ToolCall(
          name: call.name,
          arguments: call.arguments,
          result: call.result,
        )).toList(),
      );
    } catch (e, stack) {
      state = AsyncValue.error(e, stack);
      return AIResponse(
        success: false,
        message: 'Failed to execute request: $e',
      );
    }
  }
  
  /// Get available MCP tools
  Future<List<AIResponse>> getAvailableTools() async {
    if (!_isInitialized || _mcpAdapter == null) {
      return [AIResponse(
        success: false,
        message: 'MCP provider not initialized',
      )];
    }
    
    try {
      final tools = await _mcpAdapter!.listTools();
      return tools.map((tool) => AIResponse(
        success: true,
        message: tool.description ?? '',
        tools: [_convertMcpToolToLangChain(tool)],
      )).toList();
    } catch (e) {
      return [AIResponse(
        success: false,
        message: 'Failed to get tools: $e',
      )];
    }
  }
  
  /// Add MCP server configuration
  void addServer(MCPServerConfig server) {
    _mcpAdapter?.addServer(server);
  }
  
  /// Remove MCP server
  void removeServer(String serverId) {
    _mcpAdapter?.removeServer(serverId);
  }
  
  /// Get configured servers
  List<MCPServerConfig> getConfiguredServers() {
    return _mcpAdapter?.getConfiguredServers() ?? [];
  }
  
  /// Get active servers
  List<String> getActiveServers() {
    return _mcpAdapter?.getActiveServerIds() ?? [];
  }
  
  /// Shutdown provider
  Future<void> shutdown() async {
    await _mcpAdapter?.shutdown();
    _isInitialized = false;
    state = const AsyncValue.data(AIResponse(
      success: true,
      message: 'MCP provider shutdown complete',
    ));
  }
  
  /// Check if initialized
  bool get isInitialized => _isInitialized;
}

/// Provider for MCP AI functionality
final mcpAIProvider = StateNotifierProvider<McpAIProvider, AsyncValue<AIResponse>>((ref) {
  return McpAIProvider(ref);
});

/// AI Response wrapper
class AIResponse {
  final bool success;
  final String message;
  final List<ChatTool>? tools;
  final List<ToolCall>? toolCalls;
  
  AIResponse({
    required this.success,
    required this.message,
    this.tools,
    this.toolCalls,
  });
}

/// Tool call wrapper
class ToolCall {
  final String name;
  final Map<String, dynamic> arguments;
  final dynamic result;
  
  ToolCall({
    required this.name,
    required this.arguments,
    this.result,
  });
}