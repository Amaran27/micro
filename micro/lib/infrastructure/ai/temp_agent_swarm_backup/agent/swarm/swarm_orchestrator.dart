/// Swarm Intelligence Orchestrator
/// Coordinates multiple specialist agents to solve complex tasks
/// Uses LLM to dynamically generate specialist definitions based on task complexity

import 'package:micro/infrastructure/ai/agent/plan_execute_agent.dart';
import 'package:micro/infrastructure/ai/agent/swarm/blackboard.dart';
import 'package:micro/infrastructure/ai/agent/tools/tool_registry.dart';
import 'package:micro/infrastructure/ai/agent/models/agent_models.dart';
import 'package:micro/infrastructure/ai/swarm_settings_service.dart';
import 'dart:convert';
import 'dart:async'; // retained for potential future per-specialist time slicing (no global planning timeout now)

/// Specialist definition generated by meta-planning LLM
class SpecialistDefinition {
  final String id;
  final String role;
  final String systemPrompt;
  final String subtask;
  final List<String> requiredTools;
  final List<String> requiredCapabilities;
  final double priority; // 0.0-1.0, higher = execute earlier

  const SpecialistDefinition({
    required this.id,
    required this.role,
    required this.systemPrompt,
    required this.subtask,
    required this.requiredTools,
    required this.requiredCapabilities,
    this.priority = 0.5,
  });

  factory SpecialistDefinition.fromJson(Map<String, dynamic> json) {
    final id = (json['id'] ?? json['identifier'] ?? 'spec_unknown').toString();
    final role =
        (json['role'] ?? json['name'] ?? 'unnamed_specialist').toString();
    final systemPrompt = (json['systemPrompt'] ??
            json['system_prompt'] ??
            json['instructions'] ??
            'You are a focused specialist. Carry out your subtask.')
        .toString();
    final subtask =
        (json['subtask'] ?? json['task'] ?? 'No subtask specified').toString();
    final requiredToolsRaw =
        (json['requiredTools'] ?? json['tools'] ?? json['required_tools']);
    final requiredCapabilitiesRaw = (json['requiredCapabilities'] ??
        json['capabilities'] ??
        json['required_capabilities']);
    final requiredTools =
        requiredToolsRaw is List ? requiredToolsRaw.cast<String>() : <String>[];
    final requiredCapabilities = requiredCapabilitiesRaw is List
        ? requiredCapabilitiesRaw.cast<String>()
        : <String>[];
    final priorityVal = json['priority'];
    final priority = priorityVal is num ? priorityVal.toDouble() : 0.5;
    return SpecialistDefinition(
      id: id,
      role: role,
      systemPrompt: systemPrompt,
      subtask: subtask,
      requiredTools: requiredTools,
      requiredCapabilities: requiredCapabilities,
      priority: priority,
    );
  }

  Map<String, dynamic> toJson() => {
        'id': id,
        'role': role,
        'systemPrompt': systemPrompt,
        'subtask': subtask,
        'requiredTools': requiredTools,
        'requiredCapabilities': requiredCapabilities,
        'priority': priority,
      };
}

/// Result from swarm execution
class SwarmResult {
  final String goal;
  final List<SpecialistDefinition> specialists;
  final Blackboard blackboard;
  final List<SpecialistExecutionResult> executionResults;
  final bool converged;
  final int totalSpecialistsUsed;
  final Duration totalDuration;
  final int estimatedTokensUsed;
  final double estimatedCost;
  final String? error;

  const SwarmResult({
    required this.goal,
    required this.specialists,
    required this.blackboard,
    required this.executionResults,
    required this.converged,
    required this.totalSpecialistsUsed,
    required this.totalDuration,
    required this.estimatedTokensUsed,
    required this.estimatedCost,
    this.error,
  });

  Map<String, dynamic> toJson() => {
        'goal': goal,
        'specialists': specialists.map((s) => s.toJson()).toList(),
        'blackboardFacts': blackboard.getAllFacts(),
        'totalSpecialistsUsed': totalSpecialistsUsed,
        'converged': converged,
        'totalDurationMs': totalDuration.inMilliseconds,
        'estimatedTokensUsed': estimatedTokensUsed,
        'estimatedCost': estimatedCost,
        'error': error,
      };
}

/// Result from individual specialist execution
class SpecialistExecutionResult {
  final String specialistId;
  final String role;
  final AgentResult agentResult;
  final int factsWritten;
  final Duration duration;
  final int tokensUsed;

  const SpecialistExecutionResult({
    required this.specialistId,
    required this.role,
    required this.agentResult,
    required this.factsWritten,
    required this.duration,
    required this.tokensUsed,
  });
}

/// Internal evaluation result container
class _EvaluationResult {
  final bool approved;
  final String feedback;
  final Duration duration;
  final int estimatedTokens;

  const _EvaluationResult({
    required this.approved,
    required this.feedback,
    required this.duration,
    required this.estimatedTokens,
  });
}

/// Internal clarification result container
class _ClarificationResult {
  final bool needsClarification;
  final List<String> questions;
  final String reason;
  final Duration duration;
  final int estimatedTokens;

  const _ClarificationResult({
    required this.needsClarification,
    required this.questions,
    required this.reason,
    required this.duration,
    required this.estimatedTokens,
  });
}

/// Swarm Intelligence Orchestrator
///
/// Workflow:
/// 1. Meta-planning: LLM analyzes task complexity and generates specialist team
/// 2. Sequential execution: Each specialist runs, writes to blackboard
/// 3. Convergence check: Verify all objectives met
/// 4. Conflict resolution: Handle disagreements between specialists
class SwarmOrchestrator {
  final LanguageModel languageModel;
  final ToolRegistry toolRegistry;
  final int? overrideMaxSpecialists; // optional caller override
  final Duration maxDuration;
  final bool useTOONCompression;

  SwarmOrchestrator({
    required this.languageModel,
    required this.toolRegistry,
    int? maxSpecialists, // legacy param for backward compatibility
    this.maxDuration = const Duration(minutes: 5),
    this.useTOONCompression = true,
  }) : overrideMaxSpecialists = maxSpecialists;

  /// Execute a complex task using swarm intelligence
  Future<SwarmResult> execute(
    String goal, {
    Map<String, dynamic>? context,
    List<String>? constraints,
  }) async {
    final startTime = DateTime.now();
    final blackboard = Blackboard();
    int totalTokens = 0;
    int planningRetries = 0;
    const int maxPlanningRetries = 0; // disable retry to reduce latency

    try {
      // =============================================================
      // Clarification Phase (Pre Meta-Planning)
      // -------------------------------------------------------------
      // Before generating specialists we perform a very cheap LLM
      // classification to determine if the user's goal is potentially
      // ambiguous, missing constraints, or likely to yield low quality
      // results without confirmation. If clarification is needed we
      // return early with questions written to the blackboard so the UI
      // can ask the user and re-run once answered. This keeps latency
      // low for clear goals and prevents wasted planning cycles.
      // Emits a SWARM_METRIC line for observability.
      // =============================================================
      final clarificationStart = DateTime.now();
      final clarification = await _clarificationCheck(goal);
      final clarificationDuration =
          DateTime.now().difference(clarificationStart);
      if (clarification != null && clarification.needsClarification) {
        // Write clarification facts
        blackboard.put('clarification_needed', true,
            author: 'clarifier', confidence: 0.95);
        if (clarification.questions.isNotEmpty) {
          blackboard.put('clarification_questions', clarification.questions,
              author: 'clarifier', confidence: 0.9);
        }
        blackboard.put('clarification_reason', clarification.reason,
            author: 'clarifier', confidence: 0.85);
        print(
            'SWARM_METRIC phase=clarification duration_ms=${clarificationDuration.inMilliseconds} needed=true questions=${clarification.questions.length}');

        // Create synthetic execution result to surface in UI history
        final synthetic = SpecialistExecutionResult(
          specialistId: 'clarifier',
          role: 'goal_clarifier',
          agentResult: AgentResult(
            planId: 'swarm_goal_clarifier',
            finalStatus: ExecutionStatus.completed,
            result: json.encode({
              'needs_clarification': true,
              'questions': clarification.questions,
              'reason': clarification.reason,
            }),
            stepsCompleted: 1,
            stepsFailed: 0,
            totalDurationSeconds: clarificationDuration.inSeconds,
          ),
          factsWritten: 3,
          duration: clarificationDuration,
          tokensUsed: clarification.estimatedTokens,
        );

        final totalDuration = DateTime.now().difference(startTime);
        totalTokens += clarification.estimatedTokens;
        return SwarmResult(
          goal: goal,
          specialists: const [],
          blackboard: blackboard,
          executionResults: [synthetic],
          converged: false,
          totalSpecialistsUsed: 1,
          totalDuration: totalDuration,
          estimatedTokensUsed: totalTokens,
          estimatedCost: (totalTokens / 1000000) * 0.60,
        );
      } else {
        print(
            'SWARM_METRIC phase=clarification duration_ms=${clarificationDuration.inMilliseconds} needed=false');
        if (clarification != null) {
          totalTokens += clarification
              .estimatedTokens; // account for tokens cost even if not needed
        }
      }

      // Step 1: Meta-planning - generate specialist team
      print('üîç Meta-planning: Analyzing task complexity...');
      final planningStart = DateTime.now();
      List<SpecialistDefinition> specialists = [];
      while (planningRetries <= maxPlanningRetries && specialists.isEmpty) {
        specialists = await _generateSpecialistTeam(
          goal,
          context: context,
          constraints: constraints,
        );
        if (specialists.isEmpty) {
          planningRetries++;
          if (planningRetries <= maxPlanningRetries) {
            print(
                'üîÅ Meta-planning produced 0 specialists. Retrying ($planningRetries/$maxPlanningRetries)...');
          } else {
            print(
                '‚ö†Ô∏è  Meta-planning produced empty list; using fallback specialist.');
          }
        }
      }

      final planningDuration = DateTime.now().difference(planningStart);
      // SWARM_METRIC: captures meta-planning latency and team size for diagnostics
      print(
          'SWARM_METRIC phase=planning duration_ms=${planningDuration.inMilliseconds} specialists=${specialists.length}');

      totalTokens += 500; // Estimate for meta-planning

      print('ü§ñ Generated ${specialists.length} specialists');

      // Determine effective max specialists (override > persisted setting)
      final effectiveMax =
          overrideMaxSpecialists ?? await _loadPersistedMaxSpecialists();

      // Limit to effectiveMax
      final limitedSpecialists = specialists.take(effectiveMax).toList();
      if (specialists.length > effectiveMax) {
        print(
            '‚ö†Ô∏è  Limited from ${specialists.length} to $effectiveMax specialists (user config)');
      }

      // Sort by priority (higher priority first)
      limitedSpecialists.sort((a, b) => b.priority.compareTo(a.priority));

      // Step 2: Sequential execution
      final executionResults = <SpecialistExecutionResult>[];

      for (int i = 0; i < limitedSpecialists.length; i++) {
        final specialist = limitedSpecialists[i];

        // Check timeout
        if (DateTime.now().difference(startTime) > maxDuration) {
          print('‚è±Ô∏è  Max duration exceeded, stopping execution');
          break;
        }

        print('');
        print(
            '‚îå‚îÄ Specialist ${i + 1}/${limitedSpecialists.length}: ${specialist.role} ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ');

        try {
          final specStart = DateTime.now();
          final result = await _executeSpecialist(
            specialist,
            goal,
            blackboard,
            context: context,
          );

          executionResults.add(result);
          totalTokens += result.tokensUsed;

          print('‚îÇ ‚úÖ Completed in ${result.duration.inSeconds}s');
          print('‚îÇ Facts written: ${result.factsWritten}');
          // SWARM_METRIC: per-specialist execution latency, throughput (facts), and token estimate
          print(
              'SWARM_METRIC phase=specialist role=${specialist.role} id=${specialist.id} duration_ms=${DateTime.now().difference(specStart).inMilliseconds} facts=${result.factsWritten} tokens=${result.tokensUsed}');
        } catch (e) {
          print('‚îÇ ‚ùå Specialist ${specialist.id} failed: $e');
          // Record failure so UI reflects specialist participation
          executionResults.add(
            SpecialistExecutionResult(
              specialistId: specialist.id,
              role: specialist.role,
              agentResult: AgentResult(
                planId: 'swarm_${specialist.id}',
                finalStatus: ExecutionStatus.failed,
                result: 'Failure: $e',
                stepsCompleted: 0,
                stepsFailed: 1,
                totalDurationSeconds: 0,
              ),
              factsWritten: 0,
              duration: Duration.zero,
              tokensUsed: 0,
            ),
          );
          // SWARM_METRIC: failed specialist participation indicator
          print(
              'SWARM_METRIC phase=specialist role=${specialist.role} id=${specialist.id} status=failed');
        }
        print('‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ');
      }

      // Step 3: Convergence check
      print('');
      print('üîç Checking convergence...');
      final converged = await _checkConvergence(goal, blackboard);

      if (converged) {
        print('‚úÖ Goal achieved! All objectives met.');
      } else {
        print('‚ö†Ô∏è  Partial completion. Some objectives may not be fully met.');
      }

      // Step 4: Conflict resolution
      final conflicts = blackboard.detectConflicts();
      if (conflicts.isNotEmpty) {
        print('‚ö†Ô∏è  Conflicts detected in: ${conflicts.join(', ')}');
        print('üîß Resolving conflicts...');
        for (final key in conflicts) {
          blackboard.resolveConflict(key);
        }
        print('‚úÖ Conflicts resolved');
      }

      // Step 5: Result evaluation (lightweight, improves quality)
      final evalStart = DateTime.now();
      final evaluation = await _evaluateResult(goal, blackboard);
      if (evaluation != null) {
        // Write evaluator feedback to blackboard
        blackboard.put(
            'evaluation_status', evaluation.approved ? 'approved' : 'rejected',
            author: 'spec_evaluator', confidence: 0.9);
        if (evaluation.feedback.isNotEmpty) {
          blackboard.put('evaluation_feedback', evaluation.feedback,
              author: 'spec_evaluator', confidence: 0.8);
        }
        // Record evaluator as a synthetic specialist execution for transparency
        executionResults.add(
          SpecialistExecutionResult(
            specialistId: 'spec_evaluator',
            role: 'result_evaluator',
            agentResult: AgentResult(
              planId: 'swarm_spec_evaluator',
              finalStatus: ExecutionStatus.completed,
              result: json.encode({
                'approved': evaluation.approved,
                'feedback': evaluation.feedback
              }),
              stepsCompleted: 1,
              stepsFailed: 0,
              totalDurationSeconds:
                  DateTime.now().difference(evalStart).inSeconds,
            ),
            factsWritten: evaluation.feedback.isNotEmpty ? 2 : 1,
            duration: DateTime.now().difference(evalStart),
            tokensUsed: evaluation.estimatedTokens,
          ),
        );
        // SWARM_METRIC: evaluator latency and approval boolean (quality gate)
        print(
            'SWARM_METRIC phase=evaluation approved=${evaluation.approved} duration_ms=${DateTime.now().difference(evalStart).inMilliseconds}');
      }

      final totalDuration = DateTime.now().difference(startTime);

      // Estimate cost (assuming GLM-4.5 pricing: $0.60/MTok input, $0.11/MTok output)
      final estimatedCost = (totalTokens / 1000000) * 0.60;

      return SwarmResult(
        goal: goal,
        specialists: limitedSpecialists,
        blackboard: blackboard,
        executionResults: executionResults,
        converged:
            evaluation != null ? (converged && evaluation.approved) : converged,
        totalSpecialistsUsed: executionResults.length,
        totalDuration: totalDuration,
        estimatedTokensUsed: totalTokens,
        estimatedCost: estimatedCost,
      );
    } catch (e) {
      final totalDuration = DateTime.now().difference(startTime);

      return SwarmResult(
        goal: goal,
        specialists: [],
        blackboard: blackboard,
        executionResults: [],
        converged: false,
        totalSpecialistsUsed: 0,
        totalDuration: totalDuration,
        estimatedTokensUsed: totalTokens,
        estimatedCost: 0.0,
        error: 'Swarm failure: ${e.toString()}',
      );
    }
  }

  /// Load persisted max specialists from SwarmSettingsService
  Future<int> _loadPersistedMaxSpecialists() async {
    try {
      // Lazy import to avoid tight coupling in tests if service absent
      // Service file: infrastructure/ai/swarm_settings_service.dart
      // Using reflection-like access avoided; we import directly.
      // Placed here to keep constructor simple and allow async retrieval.
      final service = await _getSettingsService();
      return await service.getMaxSpecialists();
    } catch (_) {
      return 3; // fallback default
    }
  }

  SwarmSettingsService _getSettingsService() => SwarmSettingsService();

  /// Generate specialist team using LLM meta-planning
  Future<List<SpecialistDefinition>> _generateSpecialistTeam(
    String goal, {
    Map<String, dynamic>? context,
    List<String>? constraints,
  }) async {
    try {
      // Get available tools for planning
      final availableTools = toolRegistry.getAllMetadata();
      final toolsDescription = availableTools
          .map((t) =>
              '${t.name}: ${t.description} (capabilities: ${t.capabilities.join(', ')})')
          .join('\n');

      final metaPlanningPrompt = '''
You are a meta-planning AI. Analyze the following task and generate a team of specialist agents.

TASK GOAL:
$goal

AVAILABLE TOOLS:
$toolsDescription

${context != null ? '\nADDITIONAL CONTEXT:\n${json.encode(context)}\n' : ''}
${constraints != null && constraints.isNotEmpty ? '\nCONSTRAINTS:\n${constraints.join('\n')}\n' : ''}

Generate a team of specialists to solve this task. Each specialist should:
1. Have a specific expertise relevant to the goal
2. Have a clear subtask
3. Use appropriate tools from the available list (only list tools that will actually be used)
4. Be necessary (avoid redundant specialists)

Return ONLY valid JSON. Do not include commentary. Format:
[
  {
    "id": "spec_<role>",
    "role": "descriptive_role_name",
    "systemPrompt": "Expert in... Your task is to...",
    "subtask": "Clear description of what this specialist will do",
    "requiredTools": ["tool1", "tool2"],
    "requiredCapabilities": ["capability1", "capability2"],
    "priority": 0.9
  }
]

Aim for 3-5 high-impact specialists. Order by execution priority (highest first).
''';

      final response = await languageModel.invoke(metaPlanningPrompt);

      final responseText = response is String ? response : response.toString();
      print(
          'üß™ Meta-planning raw response (truncated 500 chars): ${responseText.substring(0, responseText.length > 500 ? 500 : responseText.length)}');

      // Parse JSON response
      try {
        final jsonMatch =
            RegExp(r'```json\s*([\s\S]*?)\s*```').firstMatch(responseText);
        final jsonStr = jsonMatch?.group(1) ?? responseText;

        final parsedDynamic = json.decode(jsonStr);
        final List<dynamic> specialistsList;
        if (parsedDynamic is List) {
          specialistsList = parsedDynamic;
        } else if (parsedDynamic is Map &&
            parsedDynamic['specialists'] is List) {
          specialistsList = parsedDynamic['specialists'] as List;
        } else {
          throw FormatException(
              'JSON did not contain a top-level list or specialists array');
        }

        final specialists = specialistsList
            .map(
                (s) => SpecialistDefinition.fromJson(s as Map<String, dynamic>))
            .toList();

        if (specialists.isEmpty) {
          print(
              '‚ö†Ô∏è  Meta-planning produced empty list, falling back to general specialist');
          return _fallbackGeneralSpecialist(goal);
        }
        return specialists;
      } catch (e) {
        print('‚ùå Failed to parse specialist team JSON: $e');
        print(
            'üß™ Raw response (first 300 chars): ${responseText.substring(0, responseText.length > 300 ? 300 : responseText.length)}');
        return _fallbackGeneralSpecialist(goal);
      }
    } catch (e) {
      // Covers failures in languageModel.invoke or prompt assembly
      print('‚ùå Meta-planning invocation failed: $e');
      return _fallbackGeneralSpecialist(goal);
    }
  }

  List<SpecialistDefinition> _fallbackGeneralSpecialist(String goal) {
    return [
      SpecialistDefinition(
        id: 'spec_general',
        role: 'general_problem_solver',
        systemPrompt:
            'You are a pragmatic general problem-solving agent. Break the goal into clear steps, execute them, and write concise factual findings to the blackboard.',
        subtask: goal,
        requiredTools: [],
        requiredCapabilities: [],
        priority: 1.0,
      ),
    ];
  }

  /// Execute a single specialist
  Future<SpecialistExecutionResult> _executeSpecialist(
    SpecialistDefinition specialist,
    String goal,
    Blackboard blackboard, {
    Map<String, dynamic>? context,
  }) async {
    final startTime = DateTime.now();

    print('‚îÇ üì• Subtask: ${specialist.subtask}');

    // Prepare context for specialist
    final blackboardContext = useTOONCompression
        ? blackboard.toTOON(sinceVersion: 0)
        : blackboard.toJSON(sinceVersion: 0);

    print(
        '‚îÇ üìã Blackboard size: ${blackboardContext.length} chars (${blackboard.factCount} facts)');

    // Build specialist prompt
    final specialistPrompt = '''
${specialist.systemPrompt}

OVERALL GOAL: $goal

YOUR SUBTASK: ${specialist.subtask}

BLACKBOARD STATE (shared memory from other specialists):
$blackboardContext

${context != null ? '\nADDITIONAL CONTEXT:\n${json.encode(context)}\n' : ''}

Analyze the information and complete your subtask. 
Output your findings as JSON with clear key-value pairs that will be written to the blackboard.

Example output format:
{
  "key1": "value1",
  "key2": "value2",
  "analysis": "your analysis",
  "recommendations": ["rec1", "rec2"]
}
''';

    // For now, simulate specialist execution (in real implementation, use PlanExecuteAgent)
    // This is where you'd instantiate PlanExecuteAgent with the specialist's system prompt
    // and execute the task

    final response = await languageModel.invoke(
      specialistPrompt,
    );

    // Handle both String and object responses
    final responseText = response is String ? response : response.toString();

    print('‚îÇ üîÑ Processing response...');

    // Parse response and write to blackboard
    int factsWritten = 0;
    try {
      // Try to extract JSON from response
      final jsonMatch =
          RegExp(r'```json\s*([\s\S]*?)\s*```').firstMatch(responseText);
      final jsonStr = jsonMatch?.group(1) ?? responseText;

      final parsed = json.decode(jsonStr) as Map<String, dynamic>;

      // Write each key-value pair to blackboard
      for (final entry in parsed.entries) {
        blackboard.put(
          entry.key,
          entry.value,
          author: specialist.id,
          confidence: 0.8, // Could be extracted from LLM response
        );
        factsWritten++;
      }
    } catch (e) {
      print('‚îÇ ‚ö†Ô∏è  Failed to parse JSON, writing raw response');
      // Fallback: write entire response as single fact
      blackboard.put(
        '${specialist.role}_output',
        responseText,
        author: specialist.id,
        confidence: 0.5,
      );
      factsWritten = 1;
    }

    final duration = DateTime.now().difference(startTime);

    // Estimate tokens used (rough estimate: ~4 chars per token)
    final tokensUsed =
        ((specialistPrompt.length + responseText.length) / 4).ceil();

    // Create a mock AgentResult (in real implementation, this comes from PlanExecuteAgent)
    final agentResult = AgentResult(
      planId: 'swarm_${specialist.id}',
      finalStatus: ExecutionStatus.completed,
      result: responseText,
      stepsCompleted: 1,
      stepsFailed: 0,
      totalDurationSeconds: duration.inSeconds,
    );

    return SpecialistExecutionResult(
      specialistId: specialist.id,
      role: specialist.role,
      agentResult: agentResult,
      factsWritten: factsWritten,
      duration: duration,
      tokensUsed: tokensUsed,
    );
  }

  /// Lightweight evaluator step to assess final blackboard against goal.
  Future<_EvaluationResult?> _evaluateResult(
      String goal, Blackboard blackboard) async {
    try {
      final facts = blackboard.getAllFacts();
      final summaryJson = json.encode(facts);
      final prompt = '''
You are a rigorous evaluator. Verify whether the following blackboard facts fully and accurately satisfy the user's goal.
Return ONLY compact JSON with fields:
{"approved": true|false, "feedback": "short explanation of gaps or risks"}

GOAL:
$goal

FACTS_JSON:
$summaryJson
''';
      final tStart = DateTime.now();
      final resp = await languageModel.invoke(prompt);
      final text = resp is String ? resp.trim() : resp.toString().trim();
      final match = RegExp(r"\{[\s\S]*\}").firstMatch(text);
      final jsonText = match?.group(0) ?? text;
      final parsed = json.decode(jsonText) as Map<String, dynamic>;
      final approved = parsed['approved'] == true;
      final feedback = (parsed['feedback'] ?? '').toString();
      final duration = DateTime.now().difference(tStart);
      // Estimate tokens (rough) using 4 chars/token
      final estTokens = ((prompt.length + text.length) / 4).ceil();
      return _EvaluationResult(
          approved: approved,
          feedback: feedback,
          duration: duration,
          estimatedTokens: estTokens);
    } catch (_) {
      // Silent failure to avoid blocking; return null to skip evaluator impact
      return null;
    }
  }

  /// Determine if we should ask the user for clarification before planning.
  /// Uses a very small prompt to keep latency and token usage minimal.
  Future<_ClarificationResult?> _clarificationCheck(String goal) async {
    try {
      final prompt =
          '''You are an ambiguity detector. Decide if the user's goal requires clarification questions before solving.
Return ONLY JSON: {"needs_clarification": true|false, "reason": "short string", "questions": ["q1", "q2", ...]}
If needs_clarification is false, return an empty questions array.
GOAL: $goal''';
      final start = DateTime.now();
      final resp = await languageModel.invoke(prompt);
      final text = resp is String ? resp.trim() : resp.toString().trim();
      final match = RegExp(r"\{[\s\S]*\}").firstMatch(text);
      final jsonText = match?.group(0) ?? text;
      final parsed = json.decode(jsonText) as Map<String, dynamic>;
      final needs = parsed['needs_clarification'] == true;
      final reason = (parsed['reason'] ?? '').toString();
      final questionsRaw = parsed['questions'];
      final questions = questionsRaw is List
          ? questionsRaw.map((e) => e.toString()).toList()
          : <String>[];
      final duration = DateTime.now().difference(start);
      final estTokens = ((prompt.length + text.length) / 4).ceil();
      return _ClarificationResult(
        needsClarification: needs,
        questions: questions,
        reason: reason,
        duration: duration,
        estimatedTokens: estTokens,
      );
    } catch (_) {
      // Silent failure; no clarification step enforced.
      return null;
    }
  }

  /// Check if goal is achieved based on blackboard state
  Future<bool> _checkConvergence(String goal, Blackboard blackboard) async {
    // Simple heuristic: if we have facts and no major errors, consider converged
    // In production, this would use LLM to verify goal achievement

    if (blackboard.factCount == 0) {
      return false;
    }

    // Check for error facts
    final facts = blackboard.getAllFacts();
    final hasErrors = facts.keys.any((k) => k.toLowerCase().contains('error'));

    if (hasErrors) {
      print('‚ö†Ô∏è  Error facts detected in blackboard');
      return false;
    }

    // In production: send goal + blackboard to LLM for verification
    // For now, assume convergence if we have >= 3 facts
    return blackboard.factCount >= 3;
  }
}
