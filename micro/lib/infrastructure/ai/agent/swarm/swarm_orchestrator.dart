/// Swarm Intelligence Orchestrator
/// Coordinates multiple specialist agents to solve complex tasks
/// Uses LLM to dynamically generate specialist definitions based on task complexity

import 'package:micro/infrastructure/ai/agent/plan_execute_agent.dart';
import 'package:micro/infrastructure/ai/agent/swarm/blackboard.dart';
import 'package:micro/infrastructure/ai/agent/tools/tool_registry.dart';
import 'package:micro/infrastructure/ai/agent/models/agent_models.dart';
import 'package:micro/infrastructure/ai/swarm_settings_service.dart';
import 'dart:convert';

/// Specialist definition generated by meta-planning LLM
class SpecialistDefinition {
  final String id;
  final String role;
  final String systemPrompt;
  final String subtask;
  final List<String> requiredTools;
  final List<String> requiredCapabilities;
  final double priority; // 0.0-1.0, higher = execute earlier

  const SpecialistDefinition({
    required this.id,
    required this.role,
    required this.systemPrompt,
    required this.subtask,
    required this.requiredTools,
    required this.requiredCapabilities,
    this.priority = 0.5,
  });

  factory SpecialistDefinition.fromJson(Map<String, dynamic> json) {
    return SpecialistDefinition(
      id: json['id'] as String,
      role: json['role'] as String,
      systemPrompt:
          json['systemPrompt'] as String? ?? json['system_prompt'] as String,
      subtask: json['subtask'] as String,
      requiredTools: (json['requiredTools'] as List?)?.cast<String>() ??
          (json['required_tools'] as List?)?.cast<String>() ??
          [],
      requiredCapabilities:
          (json['requiredCapabilities'] as List?)?.cast<String>() ??
              (json['required_capabilities'] as List?)?.cast<String>() ??
              [],
      priority: (json['priority'] as num?)?.toDouble() ?? 0.5,
    );
  }

  Map<String, dynamic> toJson() => {
        'id': id,
        'role': role,
        'systemPrompt': systemPrompt,
        'subtask': subtask,
        'requiredTools': requiredTools,
        'requiredCapabilities': requiredCapabilities,
        'priority': priority,
      };
}

/// Result from swarm execution
class SwarmResult {
  final String goal;
  final List<SpecialistDefinition> specialists;
  final Blackboard blackboard;
  final List<SpecialistExecutionResult> executionResults;
  final bool converged;
  final int totalSpecialistsUsed;
  final Duration totalDuration;
  final int estimatedTokensUsed;
  final double estimatedCost;
  final String? error;

  const SwarmResult({
    required this.goal,
    required this.specialists,
    required this.blackboard,
    required this.executionResults,
    required this.converged,
    required this.totalSpecialistsUsed,
    required this.totalDuration,
    required this.estimatedTokensUsed,
    required this.estimatedCost,
    this.error,
  });

  Map<String, dynamic> toJson() => {
        'goal': goal,
        'specialists': specialists.map((s) => s.toJson()).toList(),
        'blackboardFacts': blackboard.getAllFacts(),
        'totalSpecialistsUsed': totalSpecialistsUsed,
        'converged': converged,
        'totalDurationMs': totalDuration.inMilliseconds,
        'estimatedTokensUsed': estimatedTokensUsed,
        'estimatedCost': estimatedCost,
        'error': error,
      };
}

/// Result from individual specialist execution
class SpecialistExecutionResult {
  final String specialistId;
  final String role;
  final AgentResult agentResult;
  final int factsWritten;
  final Duration duration;
  final int tokensUsed;

  const SpecialistExecutionResult({
    required this.specialistId,
    required this.role,
    required this.agentResult,
    required this.factsWritten,
    required this.duration,
    required this.tokensUsed,
  });
}

/// Swarm Intelligence Orchestrator
///
/// Workflow:
/// 1. Meta-planning: LLM analyzes task complexity and generates specialist team
/// 2. Sequential execution: Each specialist runs, writes to blackboard
/// 3. Convergence check: Verify all objectives met
/// 4. Conflict resolution: Handle disagreements between specialists
class SwarmOrchestrator {
  final LanguageModel languageModel;
  final ToolRegistry toolRegistry;
  final int? overrideMaxSpecialists; // optional caller override
  final Duration maxDuration;
  final bool useTOONCompression;

  SwarmOrchestrator({
    required this.languageModel,
    required this.toolRegistry,
    int? maxSpecialists, // legacy param for backward compatibility
    this.maxDuration = const Duration(minutes: 5),
    this.useTOONCompression = true,
  }) : overrideMaxSpecialists = maxSpecialists;

  /// Execute a complex task using swarm intelligence
  Future<SwarmResult> execute(
    String goal, {
    Map<String, dynamic>? context,
    List<String>? constraints,
  }) async {
    final startTime = DateTime.now();
    final blackboard = Blackboard();
    int totalTokens = 0;

    try {
      // Step 1: Meta-planning - generate specialist team
      print('üîç Meta-planning: Analyzing task complexity...');
      final specialists = await _generateSpecialistTeam(
        goal,
        context: context,
        constraints: constraints,
      );

      totalTokens += 500; // Estimate for meta-planning

      print('ü§ñ Generated ${specialists.length} specialists');

      // Determine effective max specialists (override > persisted setting)
      final effectiveMax =
          overrideMaxSpecialists ?? await _loadPersistedMaxSpecialists();

      // Limit to effectiveMax
      final limitedSpecialists = specialists.take(effectiveMax).toList();
      if (specialists.length > effectiveMax) {
        print(
            '‚ö†Ô∏è  Limited from ${specialists.length} to $effectiveMax specialists (user config)');
      }

      // Sort by priority (higher priority first)
      limitedSpecialists.sort((a, b) => b.priority.compareTo(a.priority));

      // Step 2: Sequential execution
      final executionResults = <SpecialistExecutionResult>[];

      for (int i = 0; i < limitedSpecialists.length; i++) {
        final specialist = limitedSpecialists[i];

        // Check timeout
        if (DateTime.now().difference(startTime) > maxDuration) {
          print('‚è±Ô∏è  Max duration exceeded, stopping execution');
          break;
        }

        print('');
        print(
            '‚îå‚îÄ Specialist ${i + 1}/${limitedSpecialists.length}: ${specialist.role} ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ');

        final result = await _executeSpecialist(
          specialist,
          goal,
          blackboard,
          context: context,
        );

        executionResults.add(result);
        totalTokens += result.tokensUsed;

        print('‚îÇ ‚úÖ Completed in ${result.duration.inSeconds}s');
        print('‚îÇ Facts written: ${result.factsWritten}');
        print('‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ');
      }

      // Step 3: Convergence check
      print('');
      print('üîç Checking convergence...');
      final converged = await _checkConvergence(goal, blackboard);

      if (converged) {
        print('‚úÖ Goal achieved! All objectives met.');
      } else {
        print('‚ö†Ô∏è  Partial completion. Some objectives may not be fully met.');
      }

      // Step 4: Conflict resolution
      final conflicts = blackboard.detectConflicts();
      if (conflicts.isNotEmpty) {
        print('‚ö†Ô∏è  Conflicts detected in: ${conflicts.join(', ')}');
        print('üîß Resolving conflicts...');
        for (final key in conflicts) {
          blackboard.resolveConflict(key);
        }
        print('‚úÖ Conflicts resolved');
      }

      final totalDuration = DateTime.now().difference(startTime);

      // Estimate cost (assuming GLM-4.5 pricing: $0.60/MTok input, $0.11/MTok output)
      final estimatedCost = (totalTokens / 1000000) * 0.60;

      return SwarmResult(
        goal: goal,
        specialists: limitedSpecialists,
        blackboard: blackboard,
        executionResults: executionResults,
        converged: converged,
        totalSpecialistsUsed: executionResults.length,
        totalDuration: totalDuration,
        estimatedTokensUsed: totalTokens,
        estimatedCost: estimatedCost,
      );
    } catch (e) {
      final totalDuration = DateTime.now().difference(startTime);

      return SwarmResult(
        goal: goal,
        specialists: [],
        blackboard: blackboard,
        executionResults: [],
        converged: false,
        totalSpecialistsUsed: 0,
        totalDuration: totalDuration,
        estimatedTokensUsed: totalTokens,
        estimatedCost: 0.0,
        error: e.toString(),
      );
    }
  }

  /// Load persisted max specialists from SwarmSettingsService
  Future<int> _loadPersistedMaxSpecialists() async {
    try {
      // Lazy import to avoid tight coupling in tests if service absent
      // Service file: infrastructure/ai/swarm_settings_service.dart
      // Using reflection-like access avoided; we import directly.
      // Placed here to keep constructor simple and allow async retrieval.
      final service = await _getSettingsService();
      return await service.getMaxSpecialists();
    } catch (_) {
      return 3; // fallback default
    }
  }

  SwarmSettingsService _getSettingsService() => SwarmSettingsService();

  /// Generate specialist team using LLM meta-planning
  Future<List<SpecialistDefinition>> _generateSpecialistTeam(
    String goal, {
    Map<String, dynamic>? context,
    List<String>? constraints,
  }) async {
    // Get available tools for planning
    final availableTools = toolRegistry.getAllMetadata();
    final toolsDescription = availableTools
        .map((t) =>
            '${t.name}: ${t.description} (capabilities: ${t.capabilities.join(', ')})')
        .join('\n');

    final metaPlanningPrompt = '''
You are a meta-planning AI. Analyze the following task and generate a team of specialist agents.

TASK GOAL:
$goal

AVAILABLE TOOLS:
$toolsDescription

${context != null ? '\nADDITIONAL CONTEXT:\n${json.encode(context)}\n' : ''}
${constraints != null && constraints.isNotEmpty ? '\nCONSTRAINTS:\n${constraints.join('\n')}\n' : ''}

Generate a team of specialists to solve this task. Each specialist should:
1. Have a specific expertise relevant to the goal
2. Have a clear subtask
3. Use appropriate tools from the available list
4. Be necessary (avoid redundant specialists)

Return JSON array of specialists:
[
  {
    "id": "spec_<role>",
    "role": "descriptive_role_name",
    "systemPrompt": "Expert in... Your task is to...",
    "subtask": "Clear description of what this specialist will do",
    "requiredTools": ["tool1", "tool2"],
    "requiredCapabilities": ["capability1", "capability2"],
    "priority": 0.9  // 0.0-1.0, higher = execute earlier
  }
]

Aim for 3-7 specialists maximum. Order by execution priority (most important first).
''';

    final response = await languageModel.invoke(
      metaPlanningPrompt,
    );

    // Handle both String and object responses
    final responseText = response is String ? response : response.toString();

    // Parse JSON response
    try {
      // Try to extract JSON from response (might be in code fence)
      final jsonMatch =
          RegExp(r'```json\s*([\s\S]*?)\s*```').firstMatch(responseText);
      final jsonStr = jsonMatch?.group(1) ?? responseText;

      final parsed = json.decode(jsonStr);
      final specialistsList =
          parsed is List ? parsed : (parsed['specialists'] as List);

      return specialistsList
          .map((s) => SpecialistDefinition.fromJson(s as Map<String, dynamic>))
          .toList();
    } catch (e) {
      print('‚ùå Failed to parse specialist team: $e');
      print('Response: $responseText');

      // Fallback: create a single general specialist
      return [
        SpecialistDefinition(
          id: 'spec_general',
          role: 'general_problem_solver',
          systemPrompt:
              'You are a general problem-solving agent. Analyze and complete the given task.',
          subtask: goal,
          requiredTools: [],
          requiredCapabilities: [],
          priority: 1.0,
        ),
      ];
    }
  }

  /// Execute a single specialist
  Future<SpecialistExecutionResult> _executeSpecialist(
    SpecialistDefinition specialist,
    String goal,
    Blackboard blackboard, {
    Map<String, dynamic>? context,
  }) async {
    final startTime = DateTime.now();

    print('‚îÇ üì• Subtask: ${specialist.subtask}');

    // Prepare context for specialist
    final blackboardContext = useTOONCompression
        ? blackboard.toTOON(sinceVersion: 0)
        : blackboard.toJSON(sinceVersion: 0);

    print(
        '‚îÇ üìã Blackboard size: ${blackboardContext.length} chars (${blackboard.factCount} facts)');

    // Build specialist prompt
    final specialistPrompt = '''
${specialist.systemPrompt}

OVERALL GOAL: $goal

YOUR SUBTASK: ${specialist.subtask}

BLACKBOARD STATE (shared memory from other specialists):
$blackboardContext

${context != null ? '\nADDITIONAL CONTEXT:\n${json.encode(context)}\n' : ''}

Analyze the information and complete your subtask. 
Output your findings as JSON with clear key-value pairs that will be written to the blackboard.

Example output format:
{
  "key1": "value1",
  "key2": "value2",
  "analysis": "your analysis",
  "recommendations": ["rec1", "rec2"]
}
''';

    // For now, simulate specialist execution (in real implementation, use PlanExecuteAgent)
    // This is where you'd instantiate PlanExecuteAgent with the specialist's system prompt
    // and execute the task

    final response = await languageModel.invoke(
      specialistPrompt,
    );

    // Handle both String and object responses
    final responseText = response is String ? response : response.toString();

    print('‚îÇ üîÑ Processing response...');

    // Parse response and write to blackboard
    int factsWritten = 0;
    try {
      // Try to extract JSON from response
      final jsonMatch =
          RegExp(r'```json\s*([\s\S]*?)\s*```').firstMatch(responseText);
      final jsonStr = jsonMatch?.group(1) ?? responseText;

      final parsed = json.decode(jsonStr) as Map<String, dynamic>;

      // Write each key-value pair to blackboard
      for (final entry in parsed.entries) {
        blackboard.put(
          entry.key,
          entry.value,
          author: specialist.id,
          confidence: 0.8, // Could be extracted from LLM response
        );
        factsWritten++;
      }
    } catch (e) {
      print('‚îÇ ‚ö†Ô∏è  Failed to parse JSON, writing raw response');
      // Fallback: write entire response as single fact
      blackboard.put(
        '${specialist.role}_output',
        responseText,
        author: specialist.id,
        confidence: 0.5,
      );
      factsWritten = 1;
    }

    final duration = DateTime.now().difference(startTime);

    // Estimate tokens used (rough estimate: ~4 chars per token)
    final tokensUsed =
        ((specialistPrompt.length + responseText.length) / 4).ceil();

    // Create a mock AgentResult (in real implementation, this comes from PlanExecuteAgent)
    final agentResult = AgentResult(
      planId: 'swarm_${specialist.id}',
      finalStatus: ExecutionStatus.completed,
      result: responseText,
      stepsCompleted: 1,
      stepsFailed: 0,
      totalDurationSeconds: duration.inSeconds,
    );

    return SpecialistExecutionResult(
      specialistId: specialist.id,
      role: specialist.role,
      agentResult: agentResult,
      factsWritten: factsWritten,
      duration: duration,
      tokensUsed: tokensUsed,
    );
  }

  /// Check if goal is achieved based on blackboard state
  Future<bool> _checkConvergence(String goal, Blackboard blackboard) async {
    // Simple heuristic: if we have facts and no major errors, consider converged
    // In production, this would use LLM to verify goal achievement

    if (blackboard.factCount == 0) {
      return false;
    }

    // Check for error facts
    final facts = blackboard.getAllFacts();
    final hasErrors = facts.keys.any((k) => k.toLowerCase().contains('error'));

    if (hasErrors) {
      print('‚ö†Ô∏è  Error facts detected in blackboard');
      return false;
    }

    // In production: send goal + blackboard to LLM for verification
    // For now, assume convergence if we have >= 3 facts
    return blackboard.factCount >= 3;
  }
}
